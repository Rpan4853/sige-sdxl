{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2d00f0-fbff-4fb6-a57e-d4e7258d9f7d",
   "metadata": {},
   "source": [
    "# SIGE Benchmark on GauGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2413ae-2341-4b34-af75-0aeeeb458375",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "### Installation (This may take several minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ef201-c346-46f9-ac0e-d76e4356edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n",
    "!pip install sige\n",
    "!pip install torchprofile gdown tqdm ipyplot pyyaml easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331f971-465c-4395-9232-2c5ab77ba981",
   "metadata": {},
   "source": [
    "### Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417bc8f-0f73-4d07-9d99-f017693aded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/lmxyy/sige.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6abcf-ad52-45f2-95cb-3c7b6c58b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"sige/gaugan\")\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ee0ac-14e1-40e4-89ff-809e41c3f677",
   "metadata": {},
   "source": [
    "### Get arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79136b97-9159-48eb-a110-21d2edaa0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "def get_args(args_str: str):\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Model related\n",
    "    parser.add_argument(\"--netG\", type=str, default=\"spade\")\n",
    "    parser.add_argument(\"--ngf\", type=int, default=64)\n",
    "    parser.add_argument(\"--input_nc\", type=int, default=35)\n",
    "    parser.add_argument(\"--output_nc\", type=int, default=3)\n",
    "    parser.add_argument(\n",
    "        \"--separable_conv_norm\",\n",
    "        type=str,\n",
    "        default=\"instance\",\n",
    "        choices=(\"none\", \"instance\", \"batch\"),\n",
    "        help=\"whether to use instance norm for the separable convolutions\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--norm_G\", type=str, default=\"spadesyncbatch3x3\", help=\"instance normalization or batch normalization\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_upsampling_layers\",\n",
    "        choices=(\"normal\", \"more\", \"most\"),\n",
    "        default=\"more\",\n",
    "        help=\"If 'more', adds upsampling layer between the two middle resnet blocks. \"\n",
    "        \"If 'most', also add one more upsampling + resnet layer at the end of the generator\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--norm\",\n",
    "        type=str,\n",
    "        default=\"instance\",\n",
    "        help=\"instance normalization or batch normalization [instance | batch | none]\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--config_str\", type=str, default=None, help=\"the configuration string for a specific subnet in the supernet\"\n",
    "    )\n",
    "\n",
    "    # Data related\n",
    "    parser.add_argument(\"--crop_size\", type=int, default=512)\n",
    "    parser.add_argument(\"--no_instance\", action=\"store_true\")\n",
    "    parser.add_argument(\"--aspect_ratio\", type=int, default=2)\n",
    "\n",
    "    # SIGE related\n",
    "    parser.add_argument(\"--main_block_size\", type=int, default=6)\n",
    "    parser.add_argument(\"--shortcut_block_size\", type=int, default=4)\n",
    "    parser.add_argument(\"--num_sparse_layers\", type=int, default=5)\n",
    "    parser.add_argument(\"--mask_dilate_radius\", type=int, default=1)\n",
    "    parser.add_argument(\"--downsample_dilate_radius\", type=int, default=2)\n",
    "\n",
    "    args = parser.parse_args(args_str.split(\" \"))\n",
    "    args.semantic_nc = args.input_nc + (0 if args.no_instance else 1)\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1accf193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for the vanilla GauGAN (or original GauGAN)\n",
    "vanilla_args = get_args(\"--netG spade\")\n",
    "# Arguments for vanilla GauGAN with SIGE\n",
    "sige_vanilla_args = get_args(\"--netG sige_fused_spade\")\n",
    "# Arguments for GAN Compression\n",
    "gc_args = get_args(\"--netG sub_mobile_spade --config_str 32_32_32_48_32_24_24_32\")\n",
    "# Arguments for GAN Compression with SIGE\n",
    "sige_gc_args = get_args(\"--netG sige_fused_sub_mobile_spade --config_str 32_32_32_48_32_24_24_32 --num_sparse_layers 4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13fa9d",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f928337",
   "metadata": {},
   "source": [
    "Set device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d5531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import device_synchronize, get_device\n",
    "\n",
    "device = get_device()\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e43020",
   "metadata": {},
   "source": [
    "Define Some helper functions for creating the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from utils import decode_config\n",
    "from download_helper import get_ckpt_path\n",
    "\n",
    "\n",
    "def get_model(args, tool=\"gdown\") -> nn.Module:\n",
    "    netG = args.netG\n",
    "    config = None\n",
    "    if netG == \"spade\":\n",
    "        from models.spade_generators.spade_generator import SPADEGenerator as Model\n",
    "    elif netG == \"fused_spade\":\n",
    "        from models.spade_generators.fused_spade_generator import FusedSPADEGenerator as Model\n",
    "    elif netG == \"sige_fused_spade\":\n",
    "        from models.spade_generators.sige_fused_spade_generator import SIGEFusedSPADEGenerator as Model\n",
    "    elif netG == \"sub_mobile_spade\":\n",
    "        from models.sub_mobile_spade_generators.sub_mobile_spade_generator import SubMobileSPADEGenerator as Model\n",
    "\n",
    "        config = decode_config(args.config_str)\n",
    "    elif netG == \"sige_fused_sub_mobile_spade\":\n",
    "        from models.sub_mobile_spade_generators.sige_fused_sub_mobile_spade_generator import SIGEFusedSubMobileSPADEGenerator as Model\n",
    "\n",
    "        config = decode_config(args.config_str)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown netG: [%s]!!!\" % netG)\n",
    "\n",
    "    model = Model(args, config=config)\n",
    "    pretrained_path = get_ckpt_path(args)\n",
    "    model = load_network(model, pretrained_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_network(net: nn.Module, path: str, verbose: bool = False) -> nn.Module:\n",
    "    old_state_dict = net.state_dict()\n",
    "    new_state_dict = torch.load(path)\n",
    "    state_dict = {}\n",
    "    for k, v in old_state_dict.items():\n",
    "        vv = new_state_dict[k]\n",
    "        if v.shape != vv.shape:\n",
    "            assert v.dim() == vv.dim() == 1\n",
    "            assert \"param_free_norm\" in k\n",
    "            state_dict[k] = vv[: v.shape[0]]\n",
    "        else:\n",
    "            state_dict[k] = vv\n",
    "    net.load_state_dict(state_dict)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27575180",
   "metadata": {},
   "source": [
    "Build models. **It may take some time to download the model weights. Sometimes the downloading may get stuck. You could change the downloading tool to `torch_hub` with `tool=\"torch_hub\"` and rerun the cell or download the weights manually.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla GauGAN\n",
    "vanilla_model = get_model(vanilla_args, tool=\"gdown\")\n",
    "\n",
    "# Vanilla GauGAN with SIGE\n",
    "sige_vanilla_model = get_model(sige_vanilla_args, tool=\"gdown\")\n",
    "\n",
    "# GAN Compression\n",
    "gc_model = get_model(gc_args, tool=\"gdown\")\n",
    "\n",
    "# GAN Compression with SIGE\n",
    "sige_gc_model = get_model(sige_gc_args, tool=\"gdown\")\n",
    "\n",
    "print(\"Build models successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4006c19",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "We have prepared two pairs of user edits in [`./assets`](./assets). Here, we view the ground-truth semantic label ([`assets/gt_label.npy`](assets/gt_label.npy)) and instance map ([`assets/gt_instance.npy`](assets/gt_instance.npy)) as the original map and the synthetic semantic label ([`assets/synthetic_label.npy`](assets/synthetic_label.npy)) and instance map ([`assets/synthetic_instance.npy`](assets/synthetic_instance.npy)) as the edited map. You are free to use any other pairs of data either in our benchmark dataset (see [README.md](./README.md)) or created yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e205e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "original_label = torch.from_numpy(np.load(\"assets/gt_label.npy\")).to(device)\n",
    "original_instance = torch.from_numpy(np.load(\"assets/gt_instance.npy\")).to(device)\n",
    "edited_label = torch.from_numpy(np.load(\"assets/synthetic_label.npy\")).to(device)\n",
    "edited_instance = torch.from_numpy(np.load(\"assets/synthetic_instance.npy\")).to(device)\n",
    "\n",
    "# expand a channel dimension: [H, W] -> [C, H, W]\n",
    "original_label = original_label.unsqueeze(0)\n",
    "original_instance = original_instance.unsqueeze(0)\n",
    "edited_label = edited_label.unsqueeze(0)\n",
    "edited_instance = edited_instance.unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd653d5d",
   "metadata": {},
   "source": [
    "Display the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1434e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyplot\n",
    "\n",
    "from utils import tensor2label\n",
    "\n",
    "original_label_viz = tensor2label(original_label, vanilla_args.input_nc + 1)\n",
    "edited_label_viz = tensor2label(edited_label, vanilla_args.input_nc + 1)\n",
    "\n",
    "ipyplot.plot_images(\n",
    "    (np.array(original_label_viz), np.array(edited_label_viz)), (\"Original\", \"Edited\"), img_width=vanilla_args.crop_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc64a4f",
   "metadata": {},
   "source": [
    "Process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b07db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(t: torch.Tensor) -> torch.Tensor:\n",
    "    edge = torch.zeros(t.size(), dtype=torch.uint8, device=device)\n",
    "    edge[:, :, :, 1:] = edge[:, :, :, 1:] | ((t[:, :, :, 1:] != t[:, :, :, :-1]).byte())\n",
    "    edge[:, :, :, :-1] = edge[:, :, :, :-1] | ((t[:, :, :, 1:] != t[:, :, :, :-1]).byte())\n",
    "    edge[:, :, 1:, :] = edge[:, :, 1:, :] | ((t[:, :, 1:, :] != t[:, :, :-1, :]).byte())\n",
    "    edge[:, :, :-1, :] = edge[:, :, :-1, :] | ((t[:, :, 1:, :] != t[:, :, :-1, :]).byte())\n",
    "    return edge.float()\n",
    "\n",
    "\n",
    "label_map = torch.stack((original_label, edited_label), dim=0).long()\n",
    "instance_map = torch.stack((original_instance, edited_instance), dim=0)\n",
    "\n",
    "# create one-hot label map\n",
    "b, c, h, w = label_map.shape\n",
    "assert c == 1\n",
    "c = vanilla_args.input_nc\n",
    "input_label = torch.zeros([b, c, h, w], device=device)\n",
    "input_semantics = input_label.scatter_(1, label_map, 1.0)\n",
    "\n",
    "# concatenate instance map if it exists\n",
    "if not vanilla_args.no_instance:\n",
    "    instance_edge_map = get_edges(instance_map)\n",
    "    input_semantics = torch.cat((input_semantics, instance_edge_map), dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e0485",
   "metadata": {},
   "source": [
    "Compute the difference masks. `sige` has some helper functions for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sige.utils import compute_difference_mask, dilate_mask, downsample_mask\n",
    "\n",
    "difference_mask = compute_difference_mask(input_semantics[0], input_semantics[1], eps=1e-3)\n",
    "difference_mask = dilate_mask(difference_mask, vanilla_args.mask_dilate_radius)\n",
    "\n",
    "masks = downsample_mask(\n",
    "    difference_mask, (vanilla_model.sh, vanilla_model.sw), dilation=vanilla_args.downsample_dilate_radius\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840c898",
   "metadata": {},
   "source": [
    "Visualize the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def mask_to_image(mask: torch.Tensor):\n",
    "    mask_numpy = mask.cpu().numpy()\n",
    "    image = Image.fromarray(mask_numpy)\n",
    "    image = image.resize((vanilla_args.crop_size, vanilla_args.crop_size // vanilla_args.aspect_ratio))\n",
    "    return image\n",
    "\n",
    "\n",
    "mask_image = mask_to_image(difference_mask)\n",
    "message = \"Sparsity: %.2f%%\" % (100 * difference_mask.sum() / difference_mask.numel())\n",
    "ipyplot.plot_images((np.array(mask_image),), (\"Difference Mask\",), (message,), img_width=vanilla_args.crop_size)\n",
    "\n",
    "print(\"Downsampled Masks\")\n",
    "arrays, labels, messages = [], [], []\n",
    "for i, (k, v) in enumerate(masks.items()):\n",
    "    image = mask_to_image(v)\n",
    "    arrays.append(np.array(image))\n",
    "    labels.append(\"Resolution: %dx%d\" % (k[0], k[1]))\n",
    "    messages.append(\"Sparsity: %.2f%%\" % (100 * v.sum() / v.numel()))\n",
    "ipyplot.plot_images(arrays, labels, messages, img_width=vanilla_args.crop_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faffc7a",
   "metadata": {},
   "source": [
    "## Test Models\n",
    "### Quality Results\n",
    "Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vanilla_result = vanilla_model(input_semantics[1:])\n",
    "    gc_result = gc_model(input_semantics[1:])\n",
    "\n",
    "    # SIGE model need a pre-run to determine the data shape cache the original results\n",
    "    sige_vanilla_model.set_mode(\"full\")\n",
    "    sige_vanilla_model(input_semantics[:1])\n",
    "    sige_vanilla_model.set_masks(masks)\n",
    "    sige_vanilla_model.set_mode(\"sparse\")\n",
    "    sige_vanilla_result = sige_vanilla_model(input_semantics[1:])\n",
    "\n",
    "    sige_gc_model.set_mode(\"full\")\n",
    "    sige_gc_model(input_semantics[:1])\n",
    "    sige_gc_model.set_masks(masks)\n",
    "    sige_gc_model.set_mode(\"sparse\")\n",
    "    sige_gc_result = sige_gc_model(input_semantics[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2bb64",
   "metadata": {},
   "source": [
    "Visualize the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import tensor2im\n",
    "\n",
    "vanilla_image = tensor2im(vanilla_result[0])\n",
    "sige_vanilla_image = tensor2im(sige_vanilla_result[0])\n",
    "gc_image = tensor2im(gc_result[0])\n",
    "sige_gc_image = tensor2im(sige_gc_result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfe657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyplot\n",
    "import numpy as np\n",
    "\n",
    "ipyplot.plot_images(\n",
    "    (vanilla_image, sige_vanilla_image, gc_image, sige_gc_image),\n",
    "    (\"Vanilla\", \"SIGE\", \"GAN Compression\", \"GAN Comp.+SIGE\"),\n",
    "    img_width=vanilla_args.crop_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017e817",
   "metadata": {},
   "source": [
    "### Efficiency Results\n",
    "First, let's profile the MACs of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16233aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchprofile import profile_macs\n",
    "\n",
    "# Create some dummy inputs\n",
    "dummy_inputs = (input_semantics[1:],)\n",
    "\n",
    "with torch.no_grad():\n",
    "    vanilla_macs = profile_macs(vanilla_model, dummy_inputs)\n",
    "    gc_macs = profile_macs(vanilla_model, dummy_inputs)\n",
    "\n",
    "    # For the SIGE models, we need to first run it in the `full`` mode to cache the results.\n",
    "    sige_vanilla_model.set_mode(\"full\")\n",
    "    sige_vanilla_model(*dummy_inputs)\n",
    "    sige_gc_model.set_mode(\"full\")\n",
    "    sige_gc_model(*dummy_inputs)\n",
    "\n",
    "    # We also need to set the difference mask if not set.\n",
    "    sige_vanilla_model.set_masks(masks)\n",
    "    sige_gc_model.set_masks(masks)\n",
    "\n",
    "    # Check to the `profile` mode to profile MACs. This mode is only for the MACs profiling.\n",
    "    sige_vanilla_model.set_mode(\"profile\")\n",
    "    sige_vanilla_macs = profile_macs(sige_vanilla_model, dummy_inputs)\n",
    "    sige_gc_model.set_mode(\"profile\")\n",
    "    sige_gc_macs = profile_macs(sige_gc_model, dummy_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efdc9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vanilla MACs: %.3fG\" % (vanilla_macs / 1e9))\n",
    "print(\"SIGE MACs: %.3fG\" % (sige_vanilla_macs / 1e9))\n",
    "print(\"GAN Compression MACs: %.3fG\" % (gc_macs / 1e9))\n",
    "print(\"GAN Comp.+SIGE MACs: %.3fG\" % (sige_gc_macs / 1e9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7310306",
   "metadata": {},
   "source": [
    "SIGE model has a $\\sim 18\\times$ MACs reduction. With GAN Compression, it could reduce the computation of the vanilla GauGAN by $\\sim 50\\times$. Now let's measure the latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Change these numbers if they are too large for you.\n",
    "warmup_times = 100\n",
    "test_times = 100\n",
    "\n",
    "\n",
    "def measure_latency(model: nn.Module):\n",
    "    for i in tqdm(range(warmup_times)):\n",
    "        model(*dummy_inputs)\n",
    "        device_synchronize(device)\n",
    "    start_time = time.time()\n",
    "    for i in tqdm(range(test_times)):\n",
    "        model(*dummy_inputs)\n",
    "        device_synchronize(device)\n",
    "    cost_time = time.time() - start_time\n",
    "    return cost_time, cost_time / test_times\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    vanilla_cost, vanilla_avg = measure_latency(vanilla_model)\n",
    "    gc_cost, gc_avg = measure_latency(gc_model)\n",
    "\n",
    "    # As we have already cached some dummy results for the SIGE model, no need to rerun it in the `full` mode.\n",
    "    # Check to the `sparse` mode to test the latency.\n",
    "    sige_vanilla_model.set_mode(\"sparse\")\n",
    "    sige_vanilla_cost, sige_vanilla_avg = measure_latency(sige_vanilla_model)\n",
    "    sige_gc_model.set_mode(\"sparse\")\n",
    "    sige_gc_cost, sige_gc_avg = measure_latency(sige_gc_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vanilla: Cost %.2fs Avg %.2fms\" % (vanilla_cost, vanilla_avg * 1000))\n",
    "print(\"SIGE: Cost %.2fs Avg %.2fms\" % (sige_vanilla_cost, sige_vanilla_avg * 1000))\n",
    "print(\"GAN Compression: Cost %.2fs Avg %.2fms\" % (gc_cost, gc_avg * 1000))\n",
    "print(\"GAN Comp.+SIGE: Cost %.2fs Avg %.2fms\" % (sige_gc_cost, sige_gc_avg * 1000))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sige')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0cf6e41b72e205a83a845f94a2bdbace9441702cc85c291a6aa6c207869c7c89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
